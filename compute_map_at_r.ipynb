{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "likely-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from   pathlib import Path\n",
    "from   typing import Callable, List, Literal, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
    "\n",
    "from datasets.functions_dataset import FunctionsDataset\n",
    "from datasets.utils.collate import Collater\n",
    "\n",
    "from similarity_measures.wl_similarity import WL\n",
    "from utils.lightning_module import PlagiarismModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stainless-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle parsing errors\n",
    "with open(\"datasets/errors.txt\") as f:\n",
    "    parsing_errors = [l.strip() for l in f]\n",
    "\n",
    "class FunDataset(Dataset):\n",
    "    def __init__(self, data_root: str, f: Literal[\"graph\", \"tokens\"], tensors: bool = True):\n",
    "        self.data_root = Path(data_root)\n",
    "        if f == \"tokens\":\n",
    "            ext = \".R\"            \n",
    "        else:\n",
    "            ext = \".R.txt\"\n",
    "        self.functions = sorted(list(self.data_root.glob(f\"*{ext}\")))\n",
    "        self.functions = [f for f in self.functions if str(f) not in parsing_errors]\n",
    "        self.bases = []\n",
    "        pattern = re.compile(r\"\\d*$\")\n",
    "        for function_path in self.functions:\n",
    "            base = pattern.split(function_path.name.replace(ext, \"\"))[0]\n",
    "            self.bases.append(base)\n",
    "        unique_bases = np.unique(self.bases)\n",
    "        self.base2class = {base: i for i, base in enumerate(unique_bases)}\n",
    "        self.labels = list(map(self.base2class.get, self.bases))\n",
    "        self.format = f\n",
    "        self.tensors = tensors\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.functions)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.functions[index]\n",
    "        if self.format == \"graph\":\n",
    "            function = FunctionsDataset.parse_graph(str(path), return_tensor=self.tensors)\n",
    "        else:\n",
    "            function = FunctionsDataset.tokenize(str(path), return_tensor=self.tensors,)\n",
    "        return function, self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifteen-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_embs(fn: Callable, loader: DataLoader, cuda: bool = True):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    for fs, lbs in loader:\n",
    "        labels.extend(lbs.flatten().tolist())\n",
    "        if cuda:\n",
    "            fs = fs.cuda()\n",
    "        embs = fn(fs)\n",
    "        embeddings.append(embs.cpu().numpy())\n",
    "\n",
    "    return np.concatenate(embeddings), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maps_at_r(datasets, model, f, cuda=True):\n",
    "    maps = []\n",
    "    acc_calc = AccuracyCalculator(include=(\"mean_average_precision_at_r\", \"r_precision\", \"precision_at_1\"))\n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset = FunDataset(str(dataset), f, True)\n",
    "        loader = DataLoader(dataset, 64, False, pin_memory=True, num_workers=10, collate_fn=Collater())\n",
    "        embeddings, labels = compute_embs(model, loader, cuda)\n",
    "        res = acc_calc.get_accuracy(embeddings, embeddings,\n",
    "                                    labels, labels,\n",
    "                                    embeddings_come_from_same_source=True)\n",
    "        maps.append(res[\"mean_average_precision_at_r\"])\n",
    "\n",
    "    return {\"map@r\": np.mean(maps), \"std\": np.std(maps)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-agency",
   "metadata": {},
   "source": [
    "## TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "helpful-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"tokens\"\n",
    "datasets = list(Path(\"data/text/\").glob(\"**/10\"))\n",
    "classifier_path = \"lightning_logs/version_502/checkpoints/epoch=17-step=17999.ckpt\"\n",
    "encoder_path    = \"lightning_logs/version_499/checkpoints/epoch=24-step=24324.ckpt\"\n",
    "classifier = PlagiarismModel.load_from_checkpoint(classifier_path)\n",
    "encoder    = PlagiarismModel.load_from_checkpoint(encoder_path)\n",
    "classifier.eval().cuda()\n",
    "encoder.eval().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "capable-cargo",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [04:36<00:00,  2.56s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map@r': 0.9506968377086454, 'std': 0.04194855125595338}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_at_r(datasets, encoder.model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "separate-ethics",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [04:32<00:00,  2.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map@r': 0.9594160359561821, 'std': 0.034866103106324896}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_at_r(datasets, classifier.model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rural-sewing",
   "metadata": {},
   "source": [
    "## GRAPHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numerical-joyce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"graph\"\n",
    "datasets = list(Path(\"data/graphs/\").glob(\"**/10\"))\n",
    "classifier_path = \"lightning_logs/version_472/checkpoints/epoch=10-step=1836.ckpt\"\n",
    "encoder_path    = \"lightning_logs/version_460/checkpoints/epoch=34-step=5704.ckpt\"\n",
    "classifier = PlagiarismModel.load_from_checkpoint(classifier_path)\n",
    "encoder    = PlagiarismModel.load_from_checkpoint(encoder_path)\n",
    "classifier.eval().cuda()\n",
    "encoder.eval().cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "secret-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [02:32<00:00,  1.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map@r': 0.9495405098199478, 'std': 0.04396203613427523}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_at_r(datasets, classifier.model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "stupid-galaxy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 108/108 [02:29<00:00,  1.39s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'map@r': 0.9162808992161506, 'std': 0.057962361380680824}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maps_at_r(datasets, encoder.model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-gateway",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
